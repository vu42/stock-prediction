services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: stock-prediction-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: stock_prediction
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-airflow-db.sql:/docker-entrypoint-initdb.d/init-airflow-db.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for RQ Task Queue
  redis:
    image: redis:7-alpine
    container_name: stock-prediction-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MinIO (S3-compatible storage)
  minio:
    image: minio/minio:latest
    container_name: stock-prediction-minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # FastAPI Backend
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.api
    container_name: stock-prediction-api
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/stock_prediction
      - REDIS_URL=redis://redis:6379/0
      - S3_ENDPOINT_URL=http://minio:9000
      - S3_ACCESS_KEY_ID=minioadmin
      - S3_SECRET_ACCESS_KEY=minioadmin
      - S3_PUBLIC_URL=http://13.215.215.232
      - AIRFLOW_BASE_URL=http://stock-prediction-airflow:8080
      # Must match the AIRFLOW_API_USER/PASSWORD in airflow-webserver service
      - AIRFLOW_USERNAME=airflow_api
      - AIRFLOW_PASSWORD=AirflowApi@2025!
      - DEBUG=true
    ports:
      - "8000:8000"
    volumes:
      - ../src:/app/src
      - ../scripts:/app/scripts
      - ../migrations:/app/migrations
      - ../../output:/app/output
      - ../../stock_data:/app/stock_data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # RQ Worker
  worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile.worker
    container_name: stock-prediction-worker
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/stock_prediction
      - REDIS_URL=redis://redis:6379/0
      - S3_ENDPOINT_URL=http://minio:9000
      - S3_ACCESS_KEY_ID=minioadmin
      - S3_SECRET_ACCESS_KEY=minioadmin
      - S3_PUBLIC_URL=http://13.215.215.232
    volumes:
      - ../src:/app/src
      - ../../output:/app/output
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: python -m worker.main

  # Airflow (for DAG runs) - Using Airflow 2.x for stability
  airflow-webserver:
    image: apache/airflow:2.10.4-python3.11
    container_name: stock-prediction-airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=your-fernet-key-here
      - AIRFLOW__WEBSERVER__SECRET_KEY=your-webserver-secret
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      # Fixed API user credentials (for system-to-system communication)
      - AIRFLOW_API_USER=airflow_api
      - AIRFLOW_API_PASSWORD=AirflowApi@2025!
      - PYTHONPATH=/opt/airflow/backend/src
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/stock_prediction
      # S3/MinIO credentials for artifact uploads
      - S3_ENDPOINT_URL=http://minio:9000
      - S3_ACCESS_KEY_ID=minioadmin
      - S3_SECRET_ACCESS_KEY=minioadmin
      - S3_PUBLIC_URL=http://13.215.215.232
      - _PIP_ADDITIONAL_REQUIREMENTS=pydantic-settings httpx boto3 scikit-learn sendgrid bcrypt python-jose passlib matplotlib fastapi sqlalchemy psycopg2-binary rq
    ports:
      - "8080:8080"
    volumes:
      - ../../dags:/opt/airflow/dags
      - ../src:/opt/airflow/backend/src
      - ../../output:/opt/airflow/output
    depends_on:
      postgres:
        condition: service_healthy
    command: bash -c "airflow db migrate && airflow users create --username $${AIRFLOW_API_USER} --password $${AIRFLOW_API_PASSWORD} --firstname API --lastname Service --role Admin --email api@stockprediction.local || true && (airflow webserver --port 8080 &) && exec airflow scheduler"

volumes:
  postgres_data:
  redis_data:
  minio_data:
